%!TEX root = ../main.tex

\chapter{Introduction\label{chap:introduction}}

\section{Text representation}
The human language, with its nuances and complexities, presents a significant challenge for machines to understand.
\ac{NLP} bridges this gap, and at its core lies the critical concept of text representation.
This process acts as a translator, bridging the gap between the richness of text and the numerical language that machines understand.
By effectively capturing the meaning within words and their relationships, text representation empowers \ac{NLP} models to leverage capabilities of the \ac{ML}.
From sentiment analysis to machine translation, this ability to represent meaning fuels the advancements in \ac{NLP}, enabling machines to interact with and decipher human language with ever-increasing accuracy.

\section{Evolution of text representation methods}

\ac{NLP} has undergone a significant transformation in its approach to text representation.
Early methods, such as one-hot encoding, while simple to implement, suffered from limitations in efficiency due to dimensionality and sparsity issues.

Word embedding techniques (e.g., Word2Vec, \ac{GloVe}, FastText) offered a significant improvement by capturing semantic relationships between words through high-dimensional word vectors.
However, these techniques primarily focused on local context within a limited window, hindering their ability to capture complex relationships within sentences or documents.

The emergence of deep learning architectures, particularly transformer-based models like \ac{BERT}, revolutionized the field of text representation.
These models allows to not only understand the meaning of individual words but also consider their interaction and context within a sentence or document.

\begin{figure}
  \centering
  \input{/home/ezvezdov/Programming/NLP/BP/bachelor_thesis/src/fig/tikz/evolution_text_representaion.tex}  
  \caption{Evolution of the text representation methods.}
  \label{fig:ecolution_text_representation}
\end{figure}

\section{Research objective}

This research aims to evaluate the effectiveness of various word, sentence, and paragraph representations for their subsequent application in \ac{RAG} algorithms, with a specific focus on the domain of technical \ac{QA}.