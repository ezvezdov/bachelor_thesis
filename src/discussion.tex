%!TEX root = ../main.tex

\chapter{Discussion\label{chap:discussion}}

\section{Findings}
This study explores the potential benefits of transformer-based models for text representation compared to traditional methods like FastText.
Interestingly, the SimCSE-RetroMAE-Small transformer model achieves superior performance despite having significantly fewer parameters than FastText.
This finding suggests that the inherent architecture of transformer models may be particularly adept at capturing semantic meaning within textual data.

Furthermore, the study reveals that certain monolingual models, even those not specifically trained in the Czech language used for evaluation, achieve surprisingly positive results.
This suggests that some level of semantic similarity can be identified between languages with structural similarities, even without targeted training.
However, it is important to acknowledge that these models might not reach optimal performance for tasks involving Czech text analysis.

This study observes that unsupervised training methods employed by some models (e.g., \ac{MLM} and \ac{NSP}) lead to lower performance compared to supervised training approaches.
This suggests that supervised training on high-quality, task-specific datasets might be necessary to achieve optimal performance in tasks involving semantic similarity assessment.

Results indicate that embedding generation for less segmented text is faster compared to highly segmented text.
However, the study finds that \ac{QA} accuracy is maximized when utilizing larger chunk sizes.
This suggests a potential trade-off between processing efficiency and model performance, requiring further investigation to determine the optimal balance for specific applications.

\section{Improvements for future research}
This study relies exclusively on pre-trained models for evaluation.
While these models achieve promising results, a potential avenue for future research lies in fine-tuning these models specifically for the task of assessing semantic similarity in Czech text.
Fine-tuning pre-trained models on a Czech-specific dataset tailored for semantic similarity tasks could potentially lead to further performance improvements.

The current study utilizes an English dataset for \ac{RAG} evaluation.
The optimal chunk size can vary between languages due to differences in average word length.
Therefore, a valuable future research direction involves creating a new dataset focused on technical \ac{QA} in Czech.
Testing different chunk sizes within this new dataset would be crucial for identifying the optimal configuration for Czech technical \ac{QA} tasks.

The study employs the K parameter within the \ac{RAG} evaluation process.
The initial K values were chosen proportionally to the chunk size, mirroring the default settings within the evaluation tool.
However, to optimize performance for the \ac{QA} task, further investigation into the impact of varying K values is recommended.
Evaluating a broader range of K values alongside the varying chunk sizes could lead to the identification of the optimal configuration for maximizing \ac{RAG}'s performance in the context of this specific English technical document retrieval task.
This optimal configuration could then be compared to performance on the newly created Czech \ac{QA} dataset.




% \section{DISCUSSION STRUCTURE}
% \begin{itemize}
%     \item Interpret the overall findings and their implications for choosing suitable text representations for \ac{RAG} in technical\ac{QA} tasks.
%     \item Discuss the strengths and limitations of the chosen evaluation methods.
%     \item Address potential challenges encountered during the study and suggest improvements for future research.
% \end{itemize}
