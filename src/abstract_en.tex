%!TEX root = ../main.tex

\begin{changemargin}{0.8cm}{0.8cm}

~\vfill{}

\section*{Abstract}
\vskip 0.5em

This thesis investigates the application of word and sentence embeddings in \ac{RAG} for factual \ac{QA} tasks using technical manuals.
The study explores the effectiveness of traditional FastText embeddings and advanced transformer-based models like \ac{BERT} in capturing semantic relationships within text.
We evaluate the quality of these representations using analogy tests and confusion matrix analysis on the UPV corpus set.

Subsequently, we will select optimal representations for \ac{RAG} algorithms and assess their impact on factual accuracy and computational efficiency during \ac{QA}.
By analyzing the performance with different text chunk sizes, we aim to identify the optimal configuration for factual \ac{RAG} in technical domains.
This research contributes to the field of \ac{NLP} by providing insights into selecting effective representations that balance factual accuracy and computational efficiency for \ac{QA} systems.

\vskip 1em

{\bf Keywords} \Keywords

\vskip 2.5cm

\end{changemargin}
